{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "151a863a",
   "metadata": {},
   "source": [
    "# Devide validate (test after training model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aceefde4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: (975379, 37)\n",
      "Validation size: (51336, 37)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv(r\"..\\data\\CIC-IDS2017_processed\\training\\balanced_dataset_v1.csv\")\n",
    "\n",
    "df_train, df_val = train_test_split(df, test_size=0.05, random_state=42, stratify=df[\"Label\"])\n",
    "\n",
    "print(\"Train size:\", df_train.shape)\n",
    "print(\"Validation size:\", df_val.shape)\n",
    "\n",
    "# Lưu ra file nếu muốn\n",
    "df_train.to_csv(r\"..\\data\\CIC-IDS2017_processed\\validate\\train_95.csv\", index=False)\n",
    "df_val.to_csv(r\"..\\data\\CIC-IDS2017_processed\\validate\\val_05.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5dd426",
   "metadata": {},
   "source": [
    "# Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "65623a1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:   43.2s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  2.1min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 100 out of 100 | elapsed:    0.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9992310689167299\n",
      "[[81783    15    33]\n",
      " [   12 72319     0]\n",
      " [   90     0 40824]]\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "             BENIGN       1.00      1.00      1.00     81831\n",
      "               DDoS       1.00      1.00      1.00     72331\n",
      "Unauthorized Access       1.00      1.00      1.00     40914\n",
      "\n",
      "           accuracy                           1.00    195076\n",
      "          macro avg       1.00      1.00      1.00    195076\n",
      "       weighted avg       1.00      1.00      1.00    195076\n",
      "\n",
      "RF Model saved!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import joblib\n",
    "# 1. Đọc dữ liệu\n",
    "df_all = pd.read_csv(r\"..\\data\\CIC-IDS2017_processed\\training\\all_95.csv\")\n",
    "\n",
    "# 2. Tách features (X) và label (y)\n",
    "X = df_all.drop(columns=[\"Label\"])\n",
    "y = df_all[\"Label\"]\n",
    "\n",
    "# 3. Chia train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# 4. Khởi tạo mô hình RandomForest\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=None,\n",
    "    random_state=42,\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# 5. Train\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# 6. Dự đoán\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "# 7. Đánh giá\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "joblib.dump(rf, r\"..\\Output_model\\CIC-IDS-2017\\random_forest_model.pkl\")\n",
    "joblib.dump(list(X.columns), r\"..\\Output_model\\CIC-IDS-2017\\feature_order.pkl\")\n",
    "print(\"RF Model saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ac6f77",
   "metadata": {},
   "source": [
    "# Infer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa93b7f",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff4ace5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 100 out of 100 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== RandomForest on Validation (5%) =====\n",
      "Accuracy: 0.9991429016674458\n",
      "[[21515     6    14]\n",
      " [    6 19028     0]\n",
      " [   18     0 10749]]\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "             BENIGN       1.00      1.00      1.00     21535\n",
      "               DDoS       1.00      1.00      1.00     19034\n",
      "Unauthorized Access       1.00      1.00      1.00     10767\n",
      "\n",
      "           accuracy                           1.00     51336\n",
      "          macro avg       1.00      1.00      1.00     51336\n",
      "       weighted avg       1.00      1.00      1.00     51336\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# ==== 1. Load file validation 5% ====\n",
    "df_val = pd.read_csv(r\"..\\data\\CIC-IDS2017_processed\\validate\\val_05.csv\")\n",
    "\n",
    "X_val = df_val.drop(columns=[\"Label\"])\n",
    "y_val = df_val[\"Label\"]\n",
    "\n",
    "# ==== 2. Load model đã train ====\n",
    "rf = joblib.load(r\"..Output_model\\CIC-IDS-2017\\random_forest_model.pkl\")\n",
    "\n",
    "# ==== 3. Infer & đánh giá ====\n",
    "# --- RandomForest ---\n",
    "y_pred_rf = rf.predict(X_val)\n",
    "print(\"\\n===== RandomForest on Validation (5%) =====\")\n",
    "print(\"Accuracy:\", accuracy_score(y_val, y_pred_rf))\n",
    "print(confusion_matrix(y_val, y_pred_rf))\n",
    "print(classification_report(y_val, y_pred_rf))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b670001",
   "metadata": {},
   "source": [
    "## Infer test on 10 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0e1a48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict labels ['Unauthorized Access' 'DDoS' 'DDoS' 'DDoS' 'Unauthorized Access' 'BENIGN'\n",
      " 'BENIGN' 'DDoS' 'DDoS' 'Unauthorized Access']\n",
      "Ground truth labels 0    Unauthorized Access\n",
      "1                   DDoS\n",
      "2                   DDoS\n",
      "3                   DDoS\n",
      "4    Unauthorized Access\n",
      "5                 BENIGN\n",
      "6                 BENIGN\n",
      "7                   DDoS\n",
      "8                   DDoS\n",
      "9    Unauthorized Access\n",
      "Name: Label, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "df_val = pd.read_csv(r\"..\\data\\CIC-IDS2017_processed\\validate\\val_05.csv\")\n",
    "\n",
    "X_val = df_val.drop(columns=[\"Label\"])\n",
    "y_val = df_val[\"Label\"]\n",
    "\n",
    "rf = joblib.load(r\"..\\Output_model\\CIC-IDS-2017\\random_forest_model.pkl\")\n",
    "\n",
    "y_pred_rf = rf.predict(X_val[0:10])\n",
    "print(\"Predict labels\",y_pred_rf)\n",
    "print(\"Ground truth labels\", y_val[0:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389f430a",
   "metadata": {},
   "source": [
    "## Infer + norm + test (using input raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7c85b858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All columns are present.\n",
      "   PSH Flag Count  min_seg_size_forward  Flow IAT Max  Flow IAT Min  \\\n",
      "0               0                    20             3             3   \n",
      "1               0                    20           109           109   \n",
      "2               0                    20            52            52   \n",
      "3               0                    20            34            34   \n",
      "4               0                    20             3             3   \n",
      "5               0                    20          1022          1022   \n",
      "6               0                    20             4             4   \n",
      "7               0                    20            42            42   \n",
      "8               0                    20             4             4   \n",
      "9               0                    20             4             4   \n",
      "\n",
      "   ACK Flag Count  Destination Port  Bwd Packet Length Mean  \\\n",
      "0               1             54865                     0.0   \n",
      "1               1             55054                     6.0   \n",
      "2               1             55055                     6.0   \n",
      "3               1             46236                     6.0   \n",
      "4               1             54863                     0.0   \n",
      "5               1             54871                     0.0   \n",
      "6               1             54925                     0.0   \n",
      "7               1             54925                     6.0   \n",
      "8               1              9282                     0.0   \n",
      "9               1             55153                     0.0   \n",
      "\n",
      "   Bwd Packet Length Max  Bwd Packet Length Min  Init_Win_bytes_forward  ...  \\\n",
      "0                      0                      0                      33  ...   \n",
      "1                      6                      6                      29  ...   \n",
      "2                      6                      6                      29  ...   \n",
      "3                      6                      6                      31  ...   \n",
      "4                      0                      0                      32  ...   \n",
      "5                      0                      0                      32  ...   \n",
      "6                      0                      0                      32  ...   \n",
      "7                      6                      6                      32  ...   \n",
      "8                      0                      0                      32  ...   \n",
      "9                      0                      0                     946  ...   \n",
      "\n",
      "   Fwd Packet Length Min  Subflow Fwd Packets  Bwd IAT Max  \\\n",
      "0                      6                    2            0   \n",
      "1                      6                    1            0   \n",
      "2                      6                    1            0   \n",
      "3                      6                    1            0   \n",
      "4                      6                    2            0   \n",
      "5                      6                    2            0   \n",
      "6                      6                    2            0   \n",
      "7                      6                    1            0   \n",
      "8                      6                    2            0   \n",
      "9                      6                    2            0   \n",
      "\n",
      "   Packet Length Variance  Fwd IAT Mean  Flow Duration  Fwd IAT Total  \\\n",
      "0                0.000000           3.0              3              3   \n",
      "1                0.000000           0.0            109              0   \n",
      "2                0.000000           0.0             52              0   \n",
      "3                0.000000           0.0             34              0   \n",
      "4                0.000000           3.0              3              3   \n",
      "5                0.000000        1022.0           1022           1022   \n",
      "6                0.000000           4.0              4              4   \n",
      "7                0.000000           0.0             42              0   \n",
      "8                0.000000           4.0              4              4   \n",
      "9              208.333333           4.0              4              4   \n",
      "\n",
      "   Bwd IAT Std  Flow IAT Mean   Label  \n",
      "0          0.0            3.0  BENIGN  \n",
      "1          0.0          109.0  BENIGN  \n",
      "2          0.0           52.0  BENIGN  \n",
      "3          0.0           34.0  BENIGN  \n",
      "4          0.0            3.0  BENIGN  \n",
      "5          0.0         1022.0  BENIGN  \n",
      "6          0.0            4.0  BENIGN  \n",
      "7          0.0           42.0  BENIGN  \n",
      "8          0.0            4.0  BENIGN  \n",
      "9          0.0            4.0  BENIGN  \n",
      "\n",
      "[10 rows x 37 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_raw = pd.read_csv(r\"..\\data\\CIC-IDS2017\\Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv\")\n",
    "current_column_names = df_raw.columns\n",
    "stripped_column_names = {col: col.strip() for col in current_column_names}\n",
    "df_raw = df_raw.rename(columns=stripped_column_names)\n",
    "importance_colums = [\n",
    "    \"PSH Flag Count\", \"min_seg_size_forward\", \"Flow IAT Max\", \"Flow IAT Min\", \"ACK Flag Count\", \"Destination Port\", \"Bwd Packet Length Mean\", \"Bwd Packet Length Max\", \"Bwd Packet Length Min\", \"Init_Win_bytes_forward\",\n",
    "    \"Fwd IAT Max\", \"Idle Mean\", \"Idle Max\", \"Avg Bwd Segment Size\", \"Bwd Packet Length Std\", \"Bwd IAT Mean\", \"Fwd IAT Std\", \"Down/Up Ratio\", \"Max Packet Length\", \"Average Packet Size\",\n",
    "    \"Min Packet Length\", \"Packet Length Std\", \"Fwd Packets/s\", \"Packet Length Mean\", \"Flow IAT Std\", \"URG Flag Count\", \"FIN Flag Count\", \"Fwd Packet Length Min\", \"Subflow Fwd Packets\", \"Bwd IAT Max\",\n",
    "    \"Packet Length Variance\", \"Fwd IAT Mean\", \"Flow Duration\", \"Fwd IAT Total\", \"Bwd IAT Std\", \"Flow IAT Mean\"\n",
    "]\n",
    "# Check cột có/không\n",
    "missing_cols = [col for col in importance_colums if col not in df_raw.columns]\n",
    "\n",
    "if not missing_cols:\n",
    "    print(\"All columns are present.\")\n",
    "\n",
    "importance_colums_with_label = importance_colums + [\"Label\"]\n",
    "df_normal_data = df_raw[importance_colums_with_label]\n",
    "print(df_normal_data[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffdc703b",
   "metadata": {},
   "source": [
    "### preprocessing raw data to infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0000bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dangn\\AppData\\Local\\Temp\\ipykernel_7416\\2901429654.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_df[col] = scaled_data[:, i].tolist()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PSH Flag Count</th>\n",
       "      <th>min_seg_size_forward</th>\n",
       "      <th>Flow IAT Max</th>\n",
       "      <th>Flow IAT Min</th>\n",
       "      <th>ACK Flag Count</th>\n",
       "      <th>Destination Port</th>\n",
       "      <th>Bwd Packet Length Mean</th>\n",
       "      <th>Bwd Packet Length Max</th>\n",
       "      <th>Bwd Packet Length Min</th>\n",
       "      <th>Init_Win_bytes_forward</th>\n",
       "      <th>...</th>\n",
       "      <th>Fwd Packet Length Min</th>\n",
       "      <th>Subflow Fwd Packets</th>\n",
       "      <th>Bwd IAT Max</th>\n",
       "      <th>Packet Length Variance</th>\n",
       "      <th>Fwd IAT Mean</th>\n",
       "      <th>Flow Duration</th>\n",
       "      <th>Fwd IAT Total</th>\n",
       "      <th>Bwd IAT Std</th>\n",
       "      <th>Flow IAT Mean</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.735674</td>\n",
       "      <td>-0.35585</td>\n",
       "      <td>-0.505203</td>\n",
       "      <td>-0.037003</td>\n",
       "      <td>0.991113</td>\n",
       "      <td>2.327831</td>\n",
       "      <td>-0.794893</td>\n",
       "      <td>-0.738327</td>\n",
       "      <td>-0.331193</td>\n",
       "      <td>-0.524330</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.133981</td>\n",
       "      <td>-0.186406</td>\n",
       "      <td>-0.282318</td>\n",
       "      <td>-0.677831</td>\n",
       "      <td>-0.428095</td>\n",
       "      <td>-0.515210</td>\n",
       "      <td>-0.487105</td>\n",
       "      <td>-0.294079</td>\n",
       "      <td>-0.585057</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.735674</td>\n",
       "      <td>-0.35585</td>\n",
       "      <td>-0.505200</td>\n",
       "      <td>-0.036864</td>\n",
       "      <td>0.991113</td>\n",
       "      <td>2.337398</td>\n",
       "      <td>-0.789538</td>\n",
       "      <td>-0.736707</td>\n",
       "      <td>-0.212335</td>\n",
       "      <td>-0.524827</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.133981</td>\n",
       "      <td>-0.251245</td>\n",
       "      <td>-0.282318</td>\n",
       "      <td>-0.677831</td>\n",
       "      <td>-0.428095</td>\n",
       "      <td>-0.515207</td>\n",
       "      <td>-0.487106</td>\n",
       "      <td>-0.294079</td>\n",
       "      <td>-0.585018</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.735674</td>\n",
       "      <td>-0.35585</td>\n",
       "      <td>-0.505202</td>\n",
       "      <td>-0.036939</td>\n",
       "      <td>0.991113</td>\n",
       "      <td>2.337449</td>\n",
       "      <td>-0.789538</td>\n",
       "      <td>-0.736707</td>\n",
       "      <td>-0.212335</td>\n",
       "      <td>-0.524827</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.133981</td>\n",
       "      <td>-0.251245</td>\n",
       "      <td>-0.282318</td>\n",
       "      <td>-0.677831</td>\n",
       "      <td>-0.428095</td>\n",
       "      <td>-0.515209</td>\n",
       "      <td>-0.487106</td>\n",
       "      <td>-0.294079</td>\n",
       "      <td>-0.585039</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.735674</td>\n",
       "      <td>-0.35585</td>\n",
       "      <td>-0.505202</td>\n",
       "      <td>-0.036963</td>\n",
       "      <td>0.991113</td>\n",
       "      <td>1.891022</td>\n",
       "      <td>-0.789538</td>\n",
       "      <td>-0.736707</td>\n",
       "      <td>-0.212335</td>\n",
       "      <td>-0.524578</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.133981</td>\n",
       "      <td>-0.251245</td>\n",
       "      <td>-0.282318</td>\n",
       "      <td>-0.677831</td>\n",
       "      <td>-0.428095</td>\n",
       "      <td>-0.515209</td>\n",
       "      <td>-0.487106</td>\n",
       "      <td>-0.294079</td>\n",
       "      <td>-0.585046</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.735674</td>\n",
       "      <td>-0.35585</td>\n",
       "      <td>-0.505203</td>\n",
       "      <td>-0.037003</td>\n",
       "      <td>0.991113</td>\n",
       "      <td>2.327730</td>\n",
       "      <td>-0.794893</td>\n",
       "      <td>-0.738327</td>\n",
       "      <td>-0.331193</td>\n",
       "      <td>-0.524454</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.133981</td>\n",
       "      <td>-0.186406</td>\n",
       "      <td>-0.282318</td>\n",
       "      <td>-0.677831</td>\n",
       "      <td>-0.428095</td>\n",
       "      <td>-0.515210</td>\n",
       "      <td>-0.487105</td>\n",
       "      <td>-0.294079</td>\n",
       "      <td>-0.585057</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.735674</td>\n",
       "      <td>-0.35585</td>\n",
       "      <td>-0.505165</td>\n",
       "      <td>-0.035662</td>\n",
       "      <td>0.991113</td>\n",
       "      <td>2.328135</td>\n",
       "      <td>-0.794893</td>\n",
       "      <td>-0.738327</td>\n",
       "      <td>-0.331193</td>\n",
       "      <td>-0.524454</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.133981</td>\n",
       "      <td>-0.186406</td>\n",
       "      <td>-0.282318</td>\n",
       "      <td>-0.677831</td>\n",
       "      <td>-0.427923</td>\n",
       "      <td>-0.515178</td>\n",
       "      <td>-0.487073</td>\n",
       "      <td>-0.294079</td>\n",
       "      <td>-0.584680</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.735674</td>\n",
       "      <td>-0.35585</td>\n",
       "      <td>-0.505203</td>\n",
       "      <td>-0.037002</td>\n",
       "      <td>0.991113</td>\n",
       "      <td>2.330868</td>\n",
       "      <td>-0.794893</td>\n",
       "      <td>-0.738327</td>\n",
       "      <td>-0.331193</td>\n",
       "      <td>-0.524454</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.133981</td>\n",
       "      <td>-0.186406</td>\n",
       "      <td>-0.282318</td>\n",
       "      <td>-0.677831</td>\n",
       "      <td>-0.428095</td>\n",
       "      <td>-0.515210</td>\n",
       "      <td>-0.487105</td>\n",
       "      <td>-0.294079</td>\n",
       "      <td>-0.585057</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.735674</td>\n",
       "      <td>-0.35585</td>\n",
       "      <td>-0.505202</td>\n",
       "      <td>-0.036952</td>\n",
       "      <td>0.991113</td>\n",
       "      <td>2.330868</td>\n",
       "      <td>-0.789538</td>\n",
       "      <td>-0.736707</td>\n",
       "      <td>-0.212335</td>\n",
       "      <td>-0.524454</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.133981</td>\n",
       "      <td>-0.251245</td>\n",
       "      <td>-0.282318</td>\n",
       "      <td>-0.677831</td>\n",
       "      <td>-0.428095</td>\n",
       "      <td>-0.515209</td>\n",
       "      <td>-0.487106</td>\n",
       "      <td>-0.294079</td>\n",
       "      <td>-0.585043</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.735674</td>\n",
       "      <td>-0.35585</td>\n",
       "      <td>-0.505203</td>\n",
       "      <td>-0.037002</td>\n",
       "      <td>0.991113</td>\n",
       "      <td>0.020369</td>\n",
       "      <td>-0.794893</td>\n",
       "      <td>-0.738327</td>\n",
       "      <td>-0.331193</td>\n",
       "      <td>-0.524454</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.133981</td>\n",
       "      <td>-0.186406</td>\n",
       "      <td>-0.282318</td>\n",
       "      <td>-0.677831</td>\n",
       "      <td>-0.428095</td>\n",
       "      <td>-0.515210</td>\n",
       "      <td>-0.487105</td>\n",
       "      <td>-0.294079</td>\n",
       "      <td>-0.585057</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.735674</td>\n",
       "      <td>-0.35585</td>\n",
       "      <td>-0.505203</td>\n",
       "      <td>-0.037002</td>\n",
       "      <td>0.991113</td>\n",
       "      <td>2.342410</td>\n",
       "      <td>-0.794893</td>\n",
       "      <td>-0.738327</td>\n",
       "      <td>-0.331193</td>\n",
       "      <td>-0.410741</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.133981</td>\n",
       "      <td>-0.186406</td>\n",
       "      <td>-0.282318</td>\n",
       "      <td>-0.677780</td>\n",
       "      <td>-0.428095</td>\n",
       "      <td>-0.515210</td>\n",
       "      <td>-0.487105</td>\n",
       "      <td>-0.294079</td>\n",
       "      <td>-0.585057</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PSH Flag Count  min_seg_size_forward  Flow IAT Max  Flow IAT Min  \\\n",
       "0       -0.735674              -0.35585     -0.505203     -0.037003   \n",
       "1       -0.735674              -0.35585     -0.505200     -0.036864   \n",
       "2       -0.735674              -0.35585     -0.505202     -0.036939   \n",
       "3       -0.735674              -0.35585     -0.505202     -0.036963   \n",
       "4       -0.735674              -0.35585     -0.505203     -0.037003   \n",
       "5       -0.735674              -0.35585     -0.505165     -0.035662   \n",
       "6       -0.735674              -0.35585     -0.505203     -0.037002   \n",
       "7       -0.735674              -0.35585     -0.505202     -0.036952   \n",
       "8       -0.735674              -0.35585     -0.505203     -0.037002   \n",
       "9       -0.735674              -0.35585     -0.505203     -0.037002   \n",
       "\n",
       "   ACK Flag Count  Destination Port  Bwd Packet Length Mean  \\\n",
       "0        0.991113          2.327831               -0.794893   \n",
       "1        0.991113          2.337398               -0.789538   \n",
       "2        0.991113          2.337449               -0.789538   \n",
       "3        0.991113          1.891022               -0.789538   \n",
       "4        0.991113          2.327730               -0.794893   \n",
       "5        0.991113          2.328135               -0.794893   \n",
       "6        0.991113          2.330868               -0.794893   \n",
       "7        0.991113          2.330868               -0.789538   \n",
       "8        0.991113          0.020369               -0.794893   \n",
       "9        0.991113          2.342410               -0.794893   \n",
       "\n",
       "   Bwd Packet Length Max  Bwd Packet Length Min  Init_Win_bytes_forward  ...  \\\n",
       "0              -0.738327              -0.331193               -0.524330  ...   \n",
       "1              -0.736707              -0.212335               -0.524827  ...   \n",
       "2              -0.736707              -0.212335               -0.524827  ...   \n",
       "3              -0.736707              -0.212335               -0.524578  ...   \n",
       "4              -0.738327              -0.331193               -0.524454  ...   \n",
       "5              -0.738327              -0.331193               -0.524454  ...   \n",
       "6              -0.738327              -0.331193               -0.524454  ...   \n",
       "7              -0.736707              -0.212335               -0.524454  ...   \n",
       "8              -0.738327              -0.331193               -0.524454  ...   \n",
       "9              -0.738327              -0.331193               -0.410741  ...   \n",
       "\n",
       "   Fwd Packet Length Min  Subflow Fwd Packets  Bwd IAT Max  \\\n",
       "0              -0.133981            -0.186406    -0.282318   \n",
       "1              -0.133981            -0.251245    -0.282318   \n",
       "2              -0.133981            -0.251245    -0.282318   \n",
       "3              -0.133981            -0.251245    -0.282318   \n",
       "4              -0.133981            -0.186406    -0.282318   \n",
       "5              -0.133981            -0.186406    -0.282318   \n",
       "6              -0.133981            -0.186406    -0.282318   \n",
       "7              -0.133981            -0.251245    -0.282318   \n",
       "8              -0.133981            -0.186406    -0.282318   \n",
       "9              -0.133981            -0.186406    -0.282318   \n",
       "\n",
       "   Packet Length Variance  Fwd IAT Mean  Flow Duration  Fwd IAT Total  \\\n",
       "0               -0.677831     -0.428095      -0.515210      -0.487105   \n",
       "1               -0.677831     -0.428095      -0.515207      -0.487106   \n",
       "2               -0.677831     -0.428095      -0.515209      -0.487106   \n",
       "3               -0.677831     -0.428095      -0.515209      -0.487106   \n",
       "4               -0.677831     -0.428095      -0.515210      -0.487105   \n",
       "5               -0.677831     -0.427923      -0.515178      -0.487073   \n",
       "6               -0.677831     -0.428095      -0.515210      -0.487105   \n",
       "7               -0.677831     -0.428095      -0.515209      -0.487106   \n",
       "8               -0.677831     -0.428095      -0.515210      -0.487105   \n",
       "9               -0.677780     -0.428095      -0.515210      -0.487105   \n",
       "\n",
       "   Bwd IAT Std  Flow IAT Mean   Label  \n",
       "0    -0.294079      -0.585057  BENIGN  \n",
       "1    -0.294079      -0.585018  BENIGN  \n",
       "2    -0.294079      -0.585039  BENIGN  \n",
       "3    -0.294079      -0.585046  BENIGN  \n",
       "4    -0.294079      -0.585057  BENIGN  \n",
       "5    -0.294079      -0.584680  BENIGN  \n",
       "6    -0.294079      -0.585057  BENIGN  \n",
       "7    -0.294079      -0.585043  BENIGN  \n",
       "8    -0.294079      -0.585057  BENIGN  \n",
       "9    -0.294079      -0.585057  BENIGN  \n",
       "\n",
       "[10 rows x 37 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "\n",
    "def scale_numerical_features(data_df, importance_colums_):\n",
    "    \"\"\"\n",
    "    Norm numerical features using StandardScaler.\n",
    "    Arguments:\n",
    "        Input:  \n",
    "            - data_df: A pandas DataFrame containing numerical features that need to be scaled.\n",
    "            - importance_colums_: A list of column names to be scaled.\n",
    "        Output:\n",
    "            - data_df: A pandas DataFrame containing the scaled numerical features in the required columns.\n",
    "    \"\"\"\n",
    "    scaler = StandardScaler()\n",
    "    numerical_data = np.array([data_df[col] for col in importance_colums_]).T\n",
    "    scaled_data = scaler.fit_transform(numerical_data)\n",
    "    for i, col in enumerate(importance_colums_):\n",
    "        data_df[col] = scaled_data[:, i].tolist()\n",
    "    return data_df\n",
    "\n",
    "df_normal_data = scale_numerical_features(df_normal_data, importance_colums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7c09aace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BENIGN' 'DDoS']\n"
     ]
    }
   ],
   "source": [
    "print(df_normal_data[\"Label\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efcfa919",
   "metadata": {},
   "source": [
    "### Infer with newdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd29f62d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128027, 36) (128027,)\n",
      "Predict labels ['DDoS' 'BENIGN' 'DDoS' 'DDoS' 'DDoS']\n",
      "Ground truth labels 18883    DDoS\n",
      "18884    DDoS\n",
      "18885    DDoS\n",
      "18886    DDoS\n",
      "18887    DDoS\n",
      "18888    DDoS\n",
      "18889    DDoS\n",
      "18890    DDoS\n",
      "18891    DDoS\n",
      "18892    DDoS\n",
      "Name: Label, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "df_ddos = df_normal_data[df_normal_data[\"Label\"] == \"DDoS\"]\n",
    "\n",
    "X_features = df_ddos.drop(columns=[\"Label\"])\n",
    "y_features = df_ddos[\"Label\"]\n",
    "\n",
    "print(X_features.shape, y_features.shape)\n",
    "\n",
    "rf = joblib.load(r\"..\\Output_model\\CIC-IDS-2017\\random_forest_model.pkl\")\n",
    "feature_order = joblib.load(r\"..\\Output_model\\CIC-IDS-2017\\feature_order.pkl\")\n",
    "X_features = X_features[feature_order]\n",
    "y_pred_rf = rf.predict(X_features[0:5])\n",
    "print(\"Predict labels\",y_pred_rf)\n",
    "print(\"Ground truth labels\", y_features[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f03de511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved scaler + feature order\n",
      "Scaled (np.array): [-4.46507239e-03 -5.70765566e-02  2.32924741e+01 -1.44700973e-02\n",
      "  5.94629439e-02 -8.86123345e-03  1.89690870e-03  4.93716877e-03\n",
      "  2.30553407e-02 -1.16573827e-02 -2.30524898e-02 -5.90002125e-03\n",
      "  6.30697453e-02  7.97997722e-03  1.34315696e-02 -2.35404603e-02\n",
      "  8.71524310e-03  2.82054544e-03 -1.13678281e-02  7.47945686e-02\n",
      "  8.69043895e-03 -7.94099942e-03  6.77509090e-03 -1.75164856e-02\n",
      " -1.33230103e-02 -3.06246978e-04 -3.11471202e-02 -1.07781678e-02\n",
      " -2.33648465e-03  7.87929861e-02 -1.10653369e-02 -1.07634481e-02\n",
      " -2.20253534e-03  8.27672213e-03 -1.75164856e-02  7.44301345e-03]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "\n",
    "# ====== 1) Fit & save scaler ======\n",
    "df_all = pd.read_csv(r\"..\\data\\CIC-IDS2017_processed\\training\\all_95.csv\")\n",
    "\n",
    "# Giả sử tất cả cột trừ \"Label\" là numeric cần scale.\n",
    "# Nếu bạn chỉ muốn scale 1 subset, thay bằng list tên cột numeric.\n",
    "feature_cols = [c for c in df_all.columns if c != \"Label\"]\n",
    "\n",
    "X = df_all[feature_cols]\n",
    "y = df_all[\"Label\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)  # chỉ fit trên train\n",
    "\n",
    "# Lưu scaler + thứ tự cột\n",
    "joblib.dump(scaler, r\"..\\Output_model\\CIC-IDS-2017\\scaler.pkl\")\n",
    "joblib.dump(feature_cols, r\"..\\Output_model\\CIC-IDS-2017\\feature_order.pkl\")\n",
    "print(\"Saved scaler + feature order\")\n",
    "\n",
    "\n",
    "# ====== 2) Load & scale một điểm duy nhất ======\n",
    "def load_scaler_and_feature_order(scaler_path, feat_path):\n",
    "    scaler = joblib.load(scaler_path)\n",
    "    feature_order = joblib.load(feat_path)\n",
    "    return scaler, feature_order\n",
    "\n",
    "def scale_single_point(point, scaler, feature_order, fill_missing=0.0):\n",
    "    \"\"\"\n",
    "    point: dict | pd.Series | pd.DataFrame(1 x n)\n",
    "    scaler: StandardScaler đã fit\n",
    "    feature_order: list[str] đúng thứ tự cột đã fit\n",
    "    fill_missing: giá trị điền khi thiếu cột (nên để 0.0 hoặc np.nan + Imputer trước đó)\n",
    "    \"\"\"\n",
    "    # Chuyển point → DataFrame 1 hàng\n",
    "    if isinstance(point, dict):\n",
    "        df = pd.DataFrame([point])\n",
    "    elif isinstance(point, pd.Series):\n",
    "        df = point.to_frame().T\n",
    "    elif isinstance(point, pd.DataFrame):\n",
    "        # đảm bảo đúng 1 hàng\n",
    "        if len(point) != 1:\n",
    "            raise ValueError(\"DataFrame point must have exactly 1 row.\")\n",
    "        df = point.copy()\n",
    "    else:\n",
    "        raise TypeError(\"point must be dict, pd.Series, or 1-row pd.DataFrame.\")\n",
    "\n",
    "    # Chỉ giữ các cột đã dùng khi fit, và sắp xếp đúng thứ tự\n",
    "    df = df.reindex(columns=feature_order)\n",
    "\n",
    "    # Điền giá trị cho cột bị thiếu\n",
    "    missing_cols = [c for c in feature_order if c not in df.columns or df[c].isna().any()]\n",
    "    if missing_cols:\n",
    "        df[missing_cols] = df[missing_cols].fillna(fill_missing)\n",
    "\n",
    "    # Nếu có cột dtype object (chuỗi), sẽ lỗi -> cần encode trước từ khi fit.\n",
    "    # Ở đây giả định tất cả numeric rồi.\n",
    "\n",
    "    # transform yêu cầu shape (1, n_features)\n",
    "    scaled = scaler.transform(df)\n",
    "    # Trả về numpy 1D hoặc dict theo cột\n",
    "    scaled_row = scaled[0]\n",
    "    return scaled_row, pd.Series(scaled_row, index=feature_order).to_dict()\n",
    "\n",
    "# ====== Ví dụ dùng ======\n",
    "if __name__ == \"__main__\":\n",
    "    scaler, feature_order = load_scaler_and_feature_order(\n",
    "        r\"..\\Output_model\\CIC-IDS-2017\\scaler.pkl\",\n",
    "        r\"..\\Output_model\\CIC-IDS-2017\\feature_order.pkl\"\n",
    "    )\n",
    "\n",
    "    # Một điểm mới (ví dụ rút từ luồng realtime)\n",
    "    new_point = {\n",
    "        \"psh_flag_count\": 0,\n",
    "        \"min_seg_size_forward\": 20,\n",
    "        \"flow_iat_max\": 1500,\n",
    "        \"flow_iat_min\": 0,\n",
    "        \"ack_flag_count\": 2,\n",
    "        \"destination_port\": 443,\n",
    "        \"bwd_packet_length_mean\": 120.5,\n",
    "        # ... điền đủ các cột bạn đã fit; cột thiếu sẽ được fill_missing\n",
    "    }\n",
    "\n",
    "    scaled_row, scaled_dict = scale_single_point(\n",
    "        new_point, scaler, feature_order, fill_missing=0.0\n",
    "    )\n",
    "    print(\"Scaled (np.array):\", scaled_row)\n",
    "    # Nếu bạn muốn đưa vào model.predict, đảm bảo dùng đúng thứ tự cột:\n",
    "    X_one = np.array(scaled_row, dtype=float).reshape(1, -1)\n",
    "    # y_hat = model.predict(X_one)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e11be33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dangn\\miniconda3\\envs\\ddos\\lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\dangn\\miniconda3\\envs\\ddos\\lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 100 out of 100 | elapsed:    0.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Đánh giá theo label gốc ===\n",
      "Accuracy: 0.4452066032038594\n",
      "Confusion matrix:\n",
      " [[127537      0]\n",
      " [158930      0]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      BENIGN       0.45      1.00      0.62    127537\n",
      "    PortScan       0.00      0.00      0.00    158930\n",
      "\n",
      "    accuracy                           0.45    286467\n",
      "   macro avg       0.22      0.50      0.31    286467\n",
      "weighted avg       0.20      0.45      0.27    286467\n",
      "\n",
      "\n",
      "=== Đánh giá theo nhóm lớn (mapping) ===\n",
      "Accuracy (category): 0.4452066032038594\n",
      "Confusion matrix (category):\n",
      " [[127537      0]\n",
      " [158930      0]]\n",
      "Classification report (category):\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "             Normal       0.45      1.00      0.62    127537\n",
      "Unauthorized Access       0.00      0.00      0.00    158930\n",
      "\n",
      "           accuracy                           0.45    286467\n",
      "          macro avg       0.22      0.50      0.31    286467\n",
      "       weighted avg       0.20      0.45      0.27    286467\n",
      "\n",
      "\n",
      "Preview dự đoán:\n",
      "y_true y_pred y_true_cat y_pred_cat\n",
      "BENIGN BENIGN     Normal     Normal\n",
      "BENIGN BENIGN     Normal     Normal\n",
      "BENIGN BENIGN     Normal     Normal\n",
      "BENIGN BENIGN     Normal     Normal\n",
      "BENIGN BENIGN     Normal     Normal\n",
      "BENIGN BENIGN     Normal     Normal\n",
      "BENIGN BENIGN     Normal     Normal\n",
      "BENIGN BENIGN     Normal     Normal\n",
      "BENIGN BENIGN     Normal     Normal\n",
      "BENIGN BENIGN     Normal     Normal\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "\n",
    "# ========= Cấu hình đường dẫn =========\n",
    "CSV_PATH = r\"C:\\Code\\DDoS-Prevention-System\\Research\\data\\CIC-IDS2017\\Friday-WorkingHours-Afternoon-PortScan.pcap_ISCX.csv\"   # file CSV cần validate\n",
    "MODEL_PATH = r\"..\\Output_model\\CIC-IDS-2017\\random_forest_model.pkl\"  # model đã train (không kèm scaler)\n",
    "SCALER_PATH = r\"..\\Output_model\\CIC-IDS-2017\\scaler.pkl\"              # scaler đã fit trên train\n",
    "FEAT_ORDER_PATH = r\"..\\Output_model\\CIC-IDS-2017\\feature_order.pkl\"   # list thứ tự cột dùng khi fit\n",
    "\n",
    "# ====== Mapping nhóm label lớn (tuỳ mục đích báo cáo) ======\n",
    "label_category_mapping = {\n",
    "    'BENIGN': 'Normal',\n",
    "    'DoS Hulk': 'DDoS',\n",
    "    'DoS GoldenEye': 'DDoS',\n",
    "    'DoS slowloris': 'DDoS',\n",
    "    'DoS Slowhttptest': 'DDoS',\n",
    "    'DDoS': 'DDoS',\n",
    "    'PortScan': 'Unauthorized Access',\n",
    "    'FTP-Patator': 'Unauthorized Access',\n",
    "    'SSH-Patator': 'Unauthorized Access',\n",
    "    'Web Attack � Brute Force': 'Unauthorized Access',\n",
    "    'Web Attack � XSS': 'Unauthorized Access',\n",
    "    'Web Attack � Sql Injection': 'Unauthorized Access',\n",
    "    'Infiltration': 'Unauthorized Access',\n",
    "    'Bot': 'Unauthorized Access',\n",
    "    'Heartbleed': 'Unauthorized Access'\n",
    "}\n",
    "\n",
    "def load_assets(model_path, scaler_path, feat_order_path):\n",
    "    model = joblib.load(model_path)\n",
    "    scaler = joblib.load(scaler_path)\n",
    "    feature_order = joblib.load(feat_order_path)\n",
    "    return model, scaler, feature_order\n",
    "\n",
    "def safe_read_csv(path):\n",
    "    df = pd.read_csv(path)\n",
    "    # Strip khoảng trắng ở tên cột\n",
    "    df.columns = [c.strip() for c in df.columns]\n",
    "    return df\n",
    "\n",
    "def coerce_numeric(df, cols):\n",
    "    \"\"\"Ép kiểu numeric cho các cột trong 'cols'; nếu lỗi -> NaN.\"\"\"\n",
    "    for c in cols:\n",
    "        df[c] = pd.to_numeric(df[c], errors='coerce')\n",
    "    return df\n",
    "\n",
    "def fillna_with_scaler_means(df, feature_order, scaler):\n",
    "    \"\"\"Điền NaN theo mean đã học trong StandardScaler (theo đúng thứ tự cột).\"\"\"\n",
    "    mean_vec = scaler.mean_\n",
    "    mean_map = {col: mean_vec[i] for i, col in enumerate(feature_order)}\n",
    "    df = df.copy()\n",
    "    for col in feature_order:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].fillna(mean_map[col])\n",
    "        else:\n",
    "            # nếu thiếu cột -> tạo cột và fill bằng mean\n",
    "            df[col] = mean_map[col]\n",
    "    return df\n",
    "\n",
    "def transform_with_scaler(df_X, feature_order, scaler):\n",
    "    # Reindex đúng thứ tự cột\n",
    "    X = df_X.reindex(columns=feature_order)\n",
    "    # Transform -> numpy\n",
    "    X_scaled = scaler.transform(X.values)\n",
    "    return X_scaled\n",
    "\n",
    "def map_to_category(labels):\n",
    "    return [label_category_mapping.get(lbl, lbl) for lbl in labels]\n",
    "\n",
    "# ================== MAIN ==================\n",
    "if __name__ == \"__main__\":\n",
    "    # 1) Load model/scaler/feature_order\n",
    "    model, scaler, feature_order = load_assets(MODEL_PATH, SCALER_PATH, FEAT_ORDER_PATH)\n",
    "\n",
    "    # 2) Đọc CSV cần validate\n",
    "    df = safe_read_csv(CSV_PATH)\n",
    "\n",
    "    # 3) Xác định cột label trong file (thường là \"Label\")\n",
    "    #    CSV mẫu bạn dán có \"Label\" cuối cùng – nhưng mình vẫn\n",
    "    #    kiểm tra linh hoạt đề phòng tên/ khoảng trắng.\n",
    "    label_col_candidates = [\"Label\", \"label\", \"Labels\"]\n",
    "    label_col = next((c for c in label_col_candidates if c in df.columns), None)\n",
    "    if label_col is None:\n",
    "        raise ValueError(f\"Không tìm thấy cột Label trong file. Có các cột: {list(df.columns)[:10]} ...\")\n",
    "\n",
    "    # 4) Chuẩn bị X, ép numeric + fillna = scaler.mean_\n",
    "    #    Lưu ý: phải dùng đúng 'feature_order' đã lưu khi train.\n",
    "    df = coerce_numeric(df, [c for c in df.columns if c != label_col])\n",
    "\n",
    "    # Một số cột có thể thiếu/trùng tên -> chuẩn hoá schema theo feature_order\n",
    "    # Điền NaN/thiếu bằng mean đã học (từ scaler)\n",
    "    df_filled = fillna_with_scaler_means(df, feature_order, scaler)\n",
    "\n",
    "    # 5) Scale theo scaler đã fit\n",
    "    X_scaled = transform_with_scaler(df_filled[feature_order], feature_order, scaler)\n",
    "\n",
    "    # 6) Predict\n",
    "    y_true = df[label_col].astype(str).values  # ground truth\n",
    "    y_pred = model.predict(X_scaled)\n",
    "\n",
    "    # 7) Đánh giá (exact labels)\n",
    "    print(\"=== Đánh giá theo label gốc ===\")\n",
    "    print(\"Accuracy:\", accuracy_score(y_true, y_pred))\n",
    "    print(\"Confusion matrix:\\n\", confusion_matrix(y_true, y_pred, labels=sorted(pd.unique(np.concatenate([y_true, y_pred])))))\n",
    "    print(\"Classification report:\\n\", classification_report(y_true, y_pred, zero_division=0))\n",
    "\n",
    "    # 8) Đánh giá theo nhóm lớn (mapping)\n",
    "    y_true_cat = map_to_category(y_true)\n",
    "    y_pred_cat = map_to_category(y_pred)\n",
    "\n",
    "    print(\"\\n=== Đánh giá theo nhóm lớn (mapping) ===\")\n",
    "    print(\"Accuracy (category):\", accuracy_score(y_true_cat, y_pred_cat))\n",
    "    print(\"Confusion matrix (category):\\n\", confusion_matrix(y_true_cat, y_pred_cat, labels=sorted(pd.unique(np.concatenate([y_true_cat, y_pred_cat])))))\n",
    "    print(\"Classification report (category):\\n\", classification_report(y_true_cat, y_pred_cat, zero_division=0))\n",
    "\n",
    "    # 9) Xem nhanh vài dòng dự đoán\n",
    "    preview = pd.DataFrame({\n",
    "        \"y_true\": y_true,\n",
    "        \"y_pred\": y_pred,\n",
    "        \"y_true_cat\": y_true_cat,\n",
    "        \"y_pred_cat\": y_pred_cat\n",
    "    }).head(10)\n",
    "    print(\"\\nPreview dự đoán:\")\n",
    "    print(preview.to_string(index=False))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ddos",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
